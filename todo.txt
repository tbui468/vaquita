    Efficiency of dbms can be estimated with number IO operations

    Use gdb to walk through code (Cherno recommended debugger to learn to read code)
        https://www.cs.yale.edu/homes/aspnes/pinewiki/C(2f)Debugging.html
        Try it on the xv6 (or the risc-v version) - would gdb even work with vm?

    https://github.com/firstcontributions/first-contributionsool
        go to this link and do a basic contribution

    Use ChatGPT to help write paper on neural network to learn
        eviction policy for pager - integration of neural networks
        into legacy code

    check out nandgame for website on how to create processor from scratch
        then try to do it using verilog

    Use Yahoo or some other database standard metric to focus on core features

    cstack.github.io for short guide to basics of SQL implementation (not complete)

    Read Edward Sciore's book on implementing a relational database
        Chapter 4: Memory Management (PDF 92)

    Use SDL and Vulkan to visualize stars/planets/moons in galaxy

    sqlite documentation has great explanation of how bytecode works

    handmade.network has cool mini projects (such as barebones OS with only a few thousand lines of C)

    OS
        James Molloy has a good website for OS dev
        use qemu
        use OS dev so that we can set up skeleton project

    Look here for two star databases:
        https://github.com/astronexus/HYG-Database
        One has around 100,000 stars, one has about 200,000 stars/objects and one database has over 2.5 million(!) stars

    valgrind --leak-check=full --show-leak-kinds=all --log-file="output.txt" -v ./../build/src/vdb sol.sql

    Walkthrough of git source code (cool!) 
        https://fabiensanglard.net/git_code_review/

    wyag.thb.lt
        writing version control software like git (pretty cool)

***********************Documentation*****************************
Example
Major components
Todos

*************************Performance***************
In debug mode:
    Takes about 1:40 to lex/parse inserting 10,000 records
    Takes about 1:40 to insert 10,000 records
In release mode:
    ~1:40 to lex/parse 10,000 records
    ~0:20 to insert 10,000 records

*******************************TODO**************************************************
    Change client api to use an opaque handle
        this will also make it easier to hide WIN32 stuff inside the implementation using preprocessor ifdef else endif

    Server should not require opaque handle anymore since user doesn't have direct access
        anymore

    Client functionality
        Opening multiple clients does NOT update database properly
            Each node is opening its own database handle with its own pager
            this shouldn't happen!  All clients should be using the same handle,
            pager, etc.  This is controlled by the server.  The client only can request
            the handle.  This is necessary since we need write/read locks later so that
            multiple nodes can't write at the same time.

            Need to copy-on-write root when a node wants to write...

        vm needs to handle own errors (lexer and parser need to handle errors better too)
            then add them to output (same as lexer and parser are currently doing)
            some code branches are hitting the asserts, which cause problems (program blocks until some bad shit happens)
                these should be errors that are recorded and sent to client

    network code needs to be pulled out into own module
        server.h/server.c for dbms server
        client.h (single header for easy drop-in) for client

    Connect sdl_app and vaquita in the easiest way possible
        just have sdl_app send sql to vaquita, get a response, and print out the response on sdl_app side
        run the sql statements

    Combine windows and *nix versions into a single client header with ifdefs
        Write out windows version of client by hand to see what's in there first
        then abstract the windows/linux stuff into own functions, and common stuff into other functions

    Priority: connect to star view client
        Have client send SQL to server, and have server execute that query and return result
            will need to rewrite structure of server

        Could have tests call the client now, and then have the client output the results to compare against expected results
        Make client work with windows so that we can use it in sdl_game
            Beej's website has a link where someone else wrote a windows version
                will need this version if we want to use it in sdl_game

    Insertions with out-of-order keys doesn't order them properly in B-Tree
        should fixed this soon too, otherwise indexing is pointless

    Rewrite tree like this:
        Meta block holds a ptr to first data block
            use this ptr to defrag and find free space if needed

        Internal nodes are the same as before
        
        Leaf nodes only hold ptrs to data
            not longer need a data block for each leaf

        Data nodes hold records + variable length data
            don't allow overflow for now to keep it simple - if not enough space in a data block to fit entire record, just allocate a new one


    Creating/dropping indexes:
        Indexes require multiple trees - we need to take records out of leaves and put them in own data blocks that
            all indices can refer to.  Could keep data nodes for variable length data, and make record nodes for fixed len record data

            Still 4 types of nodes:
                internal
                leaf
                record
                data

            in leaf, each index refers to record ptr (datacell).  Each record ptr has the node idx and idxcell idx.
            currently records are: [next|occupied|data...]
            new record data in leaf: [next|occupied|node_idx|idxcell_idx]

            datacell in data node: [next|

        Rewrite B-Tree so that:
            create index x_coords on planets.x; //only allow single indexing for now, so don't need planets(x) syntax
            drop index x_coords on planets;

            Any data type can be used as keys (string, int, (float as a key is stupid, but allow it), bool)
            leaves now only hold references to data blocks
            data blocks hold record data (including variable length data)
            data blocks can now be defragged if enough spac
            Need to be able to index by cartesian coordinates (x, y, z) so tha star app works

    Inserting records with out of order keys don't order them correctly in B-Tree (skip for now since B-Tree requires rewrite anyway)
        insert into planets (id, name, mass, atmosphere) values (5, "Neptune", 20, false), (1, "Mars", 10, true), (3, "Venus", 10, false);
        select * from planets;

        This should return Mars, Venus and then Neptune.  But it returns insertion order
        this will be need to change with rewriting of B-Tree, so just skip this for now

    joins
        cross-join
        inner-join (cross join with a condition)
        outer joins

        will need foreign keys here

    subqueries - seems like this is useful only with multiple tables (foreign keys may be needed too)
        select distinct name from (select * from planets order by name desc);
        what other subqueries could we use as tests?

        Records are tuples of data
        A record is the entire tuple of data
        A tuple is a subset of the record data (could possible be the entire thing too)
        
    copy stmt
        *this should require the csv to be cleaned, but it'll be faster than parsing and executing SQL for all the inserts
        copy stars(id, proper, dist) from "hyb_30.csv" delimiter ',' csv header;
        Essentially just make the AST for insert once, and then substitute

    Compiler may make insertion faster
        codegen.c - spits out bytecode
        vm.c - runs vm

    Load up a large database so that buffer pool can be tested
        generate script to:
            create database and table first (drop if existing)
            then add about 10 stars
            then 100
            then 1000
            then 10000
            then entire file (10000s)

    Eviction policy
        make db really big so that the program crashes because of too much memory allocated, then evict pages to fix it
        Or just manually limit number of pages allowed to hold at a time
        Use O_DIRECT to bypass OS pager

        implement LRU policy for now, but make it easy to swap algorithms (such as to clock policy or using a nn)
        make a linked list of currently cached blocks
        define MAX_BLOCKS 4
        when we need a block, scan the list and look for it
        if not found, remove last block (flush if necessary) and load in new block from disk 

    tree.c/cursor (in vdb.c) needs a massive rewrite - it's too confusing now
        start with caching the schema instead of dynamically allocating/freeing it in every tree function
        abstraction between cursor and tree is fuzzy - what responsibility should each have?
        traverse_to_first_leaf is no longer necessary - remove it
    
        cursor functions are too light - it should really be calling most of the tree.c api to do what needs to be done
            tree functions should mainly deal with nodes (which the cursor shouldn't know about)

            abstraction layers: vm -> cursor -> tree -> node

            need to pull some complexity out of tree.c and into cursor.c

        cursor abstraction:
            cursors are created when starting a new transaction, and destroyed when transaction ends (commit or not)
            a cursor is associated with a table AND an ordering (eg, by which column the records are indexed)
            a cursor has a closed and open state:
                <open stmt> opens a cursor
                <close stmt>, <commit stmt>, or <rollback stmt> closes cursor
            cursor may be before first record or one past the last record
            fetch - moves cursor to next record and returns that record
            delete - deletes record pointed to by cursor - moves cursor to next record after deletion
            update - updates records pointed to by cursor

    allocated_memory variable show -52 bytes when runnging sol.sql
        I suspect that a non-wrapper allocation function is being called somewhere
        OR free_w has a wrong size argument

    Probably should cached schema and use that whenever vdbmeta_get_schema is called rather than having to
        manually free it every single time - error prone and just makes everything look messier

    User defined primary keys
        Need to make sure keys are unique
        Need to rewrite B-Tree to not always append at end

    Subqueries

    Add tests for errors:
        insert_invalid_col_name.sql <----should report error message.  Silenty failing now when mistyped, and hard to debug
            create table planets (name string, moons int);
            insert into planets (name, gravity) values ("Earth", 9.81); //this should report error instead of setting moons to null and ignoring 9.81

        *will probably need to introduce runtime errors here (we have tokenizing and parsing(?) errors already)

    single line comments
        use c-style //

    multiline comments
        use c-style /**/

    Don't need to specify column names if inserting all values
        insert into planets values (...), (...);

    If block size is 256 and block header size is 128, it crashes if not enough room to store schema data
        the attribute names take too much space.  Need an data blocks and overflow blocks for colunm names

    Compile AST to bytecode that runs on vm
        How could this work?
            what instructions are needed?
        when inserting, attribute names should be parsed as expressions (being parsed as single tokens now)
            can remove parse_identifier_tuple function then

            insert into planets (name, mass) values ("Mars", 242), ("Venus", 242), ("Earth", 534);

        
    need checks to prevent table manipulation/creation/dropping when database not open - segfaulting now

    need to return error if table doesn't exist when insert/select/update/delete - segfaulting now

    primary keys rework
        user MUST define primary key using 'primary key' keywords
        'auto' keyword will make an autoincrementing column value
        'constraint' can be used to set primary key
        should allow this:
            create table planets (name string, moons int);
            create table planets (name string not null, id int auto);
            create table planets (name string, moons int, primary key

    Concurrency - need to get read/write locks on file
        pager can take care of this

    Transactions - need a way of rolling back changes if transaction fails
        need a way to track undos (a stack???)

    Logging - database should never be in inconsistent state if system fails
        sqlite uses a write-ahead log


    Connect cli and the database tree to get useful data - play with MariaDB or MySQL to see how they print outputs
        > open school
            database school opened
        > select * from students
            +----+------+-----+
            | id | name | age |
            +----+------+-----+
            |  1 | John |  23 |
            |  2 | Kate |  12 |
            |  3 | Timm |  22 |
            +----+------+-----+
            3 rows in set
        > close school
            database school closed
            [what message?]

    Foreign keys to connect two or more tables
        joins will be needed here

    Custom keys
        Unique or not?
        Have to rewrite tree to split/merge based on where inserted (since it will not be in order anymore)

    views

    unique constraint

    not null constraint

    group by

    joins
    
    split into client and server - use tcp sockets to connect client to server
