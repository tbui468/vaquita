*******************************TODO**************************************************
    Database System Concepts:
        Chapter 1: Introduction
        Chapter 2: Introduction to the Relational Model
            The join operation is a sequence of what two other operations?
            What does 'arity' mean?  Why must arity of two relations be the same when using the union operator?
        Chapter 3: Introduction to SQL
            select * from instructors order by age asc, salary desc; <----this should be allowed in vaquita
            How are these two SQL queries different?  Which is more correct for finding average?
                select avg(salary) from instructors where department = "CS";
                select avg(distinct salary) from instructors where departement = "CS";
            Why should this query be erroneuous?
                select count(moons), name from planets group by atmosphere;
            Does this work in vaquita?
                select avg(moons) from planets;
            The 'with' clause used to create temporary tables looks a lot like QUEL 'range of' statements
                eg, range of s is Student;

        Chapter 4: Intermediate SQL (p. 124)
            What is a natural join?
            What is one reason to use 'on' rather than 'where' when joining tables?
            Explain in simple terms the difference between an inner join and outer join?
            How are the scopes of views different from those when using 'with'?
            What does 'coalesce' function do?
            What does the 'check' constraint do?
            Why is the 'initially deferred' clause sometimes useful?
            How are assertions different from check constraints?
            Along with B+ Tree, what other data structure can be used to store an index?

        Chapter 5: Advanced SQL (p. 183)
            Give an example of when an SQL trigger could be useful
            Could a trigger be used to send an email when a user registers with a website?
            What is 'windowing' (with regards to aggregate functions)?
            What are 'rollup' and 'cube' used for?
            Are 'rollup' and 'cube' fundmental SQL commands, or can these queries be done with other SQL?

        Chapter 6: Database Design Using the E-R Model (p. 241)

    Read Database Design and Implementation
    Read Designing Data-Intensive Applications

        Do ALL exercises in Chapter 3, 4, and 5 in Database Systems using Postgres
            Solutions are on db-book.com (and database download is there too)

    Implementation of Ingres

    Implementation of Postgres

    Fix CV
        Make it ready for submission
            work: sorting and search algorithms
                  tetris, asteroids, pacman, battleship (in pygame)

            wedding website: ??? Should I put that on?

            Link github
            Languages: C/Python/SQL

    Look at bustub for architecture inspiration

    Switch over to google cpp coding style
        https://gist.github.com/davidzchen/9187878

    Redo select so that these work:
        select upper('AdbdD'), lower('AdfBZ');
        select sum(moons) from planets; 

    Lock database (for both reading/writing)

        Use a multi-reader/single-writer lock on root for now
            Just use a plain mtx_lock for now for reading/writing
            it's not fast or efficient, but it'll do for now

    Make syntax match postgresql (makes my life easier and also makes direction clearer)

    Query Execution
        Implement EXPLAIN command to show:
            Binder
            Planner
            Optimizer

        joins
            cross join
            inner join

    indexing:
        create index my_index on table_name (x, y);
        drop index my_index;

        To create index, go through primary key index and
            insert new nodes into new index.

        Meta nodes should also use idxcell and datacell format
            store index names/root as cells in meta node

    Transactions
        Watch this video on logging:
            https://www.youtube.com/watch?v=hh21I1702OY&ab_channel=CMUDatabaseGroup

            Watch from 41:30 for WAL

        Force:
            Are txns forced to write a page to disk before it can message to the world that it's committed?
            if force:
                all updates must be on disk before txn allowed to commit
            else: no-force
                updates NOT required to be on disk when txn commits
        Steal
            Example, txn1 needs more memory, but a page needs to be evicted.  If txn2 has uncommitted
            updates on a page, can txn1 steal from txn2?  Can txn1 evict txn2's uncommitted updates on
            a page (steal it)

            if steal:
                txn1 can evict page and write uncommitted txn2 updates to disk (potentially overwriting 
                last commited txn)
            else: //no steal
                if a page has uncommitted updates, cannot evict

        No-steal + Force
            easy to implement/rollback/but can't do it if data can't all fit into memory
            use shadow pages to get over memory limits


        'torn writes'
            

        If something fails part-way through, any changes should be reverted
        Need to log changes and undo if necessary

    WAL needs to include ALL writes to the table (meta, internal, leaf, and data blocks)
        when ANY change (including transaction) is made, DON'T modify in-memory data
        instead append the change to the WAL file
        if a block has to be read, it MUST check the WAL file first.
            read in-memory block
            check WAL for ALL changes...?

        if rolledback, just discard WAL
        if commited, 
        

    Page eviction
        Use O_DIRECT and O_SYNC (along with switching from fopen to open)
            to see if bypassing OS cache will speed up queries

        Write open_w wrapper that uses O_DIRECT and O_SYNC
        Set a mamimum page count based on RAM (4-8 Gb seems reasonable)

    Logging
        use an append-only log to ensure data is not lost/corrupt if system
        goes down while writing.  Write to log first before writing from
        tree to disk

    Redo projection:
        Rather than an array of structs for recordsets, use a struct of arrays
        this will make projection easy - simply drop any arrays we don't need

    update will break if string is longer than current record size
        need to properly resize datacells if strings are updated
        need to store 3 data for each string: size, capacity, overflow

    Should NOT allow duplicate keys

    strings need work
        string keys are NOT currently saved in tree nodes correctly(the pointer /len is saved right now, which doensn't do anything or at worst breaks everything)
            put in some asserts to fail if a string is used as key, or fix this to allow strings as keys

        update will not work correctly if string fields are different sizes now...

    deleted datacells in leaf are not being reclaimed right now
        this can also be fixed when we switch over to data blocks to hold records

    select * from planets; //this should report error since there is no table called planets in universe db
        this was causing problems since I kept typing the wrong table name in (this shouldn't happend again)

    If table name is omitted, also report error

    Server should not require opaque handle anymore since user doesn't have direct access
        anymore

    Client functionality
        Opening multiple clients does NOT update database properly
            Each node is opening its own database handle with its own pager
            this shouldn't happen!  All clients should be using the same handle,
            pager, etc.  This is controlled by the server.  The client only can request
            the handle.  This is necessary since we need write/read locks later so that
            multiple nodes can't write at the same time.

            Need to copy-on-write root when a node wants to write...

        vm needs to handle own errors (lexer and parser need to handle errors better too)
            then add them to output (same as lexer and parser are currently doing)
            some code branches are hitting the asserts, which cause problems (program blocks until some bad shit happens)
                these should be errors that are recorded and sent to client

    network code needs to be pulled out into own module
        server.h/server.c for dbms server
        client.h (single header for easy drop-in) for client

    Combine windows and *nix versions into a single client header with ifdefs
        Write out windows version of client by hand to see what's in there first
        then abstract the windows/linux stuff into own functions, and common stuff into other functions
    Creating/dropping indexes:
        Indexes require multiple trees - we need to take records out of leaves and put them in own data blocks that
            all indices can refer to.  Could keep data nodes for variable length data, and make record nodes for fixed len record data

            Still 4 types of nodes:
                internal
                leaf
                record
                data

            in leaf, each index refers to record ptr (datacell).  Each record ptr has the node idx and idxcell idx.
            currently records are: [next|occupied|data...]
            new record data in leaf: [next|occupied|node_idx|idxcell_idx]

            datacell in data node: [next|

        Rewrite B-Tree so that:
            create index x_coords on planets.x; //only allow single indexing for now, so don't need planets(x) syntax
            drop index x_coords on planets;

            Any data type can be used as keys (string, int, (float as a key is stupid, but allow it), bool)
            leaves now only hold references to data blocks
            data blocks hold record data (including variable length data)
            data blocks can now be defragged if enough spac
            Need to be able to index by cartesian coordinates (x, y, z) so tha star app works

    Inserting records with out of order keys don't order them correctly in B-Tree (skip for now since B-Tree requires rewrite anyway)
        insert into planets (id, name, mass, atmosphere) values (5, "Neptune", 20, false), (1, "Mars", 10, true), (3, "Venus", 10, false);
        select * from planets;

        This should return Mars, Venus and then Neptune.  But it returns insertion order
        this will be need to change with rewriting of B-Tree, so just skip this for now

    joins
        cross-join
        inner-join (cross join with a condition)
        outer joins

        will need foreign keys here

    subqueries - seems like this is useful only with multiple tables (foreign keys may be needed too)
        select distinct name from (select * from planets order by name desc);
        what other subqueries could we use as tests?

        Records are tuples of data
        A record is the entire tuple of data
        A tuple is a subset of the record data (could possible be the entire thing too)
        
    copy stmt
        *this should require the csv to be cleaned, but it'll be faster than parsing and executing SQL for all the inserts
        copy stars(id, proper, dist) from "hyb_30.csv" delimiter ',' csv header;
        Essentially just make the AST for insert once, and then substitute

    Compiler may make insertion faster
        codegen.c - spits out bytecode
        vm.c - runs vm

    Load up a large database so that buffer pool can be tested
        generate script to:
            create database and table first (drop if existing)
            then add about 10 stars
            then 100
            then 1000
            then 10000
            then entire file (10000s)

    Eviction policy
        make db really big so that the program crashes because of too much memory allocated, then evict pages to fix it
        Or just manually limit number of pages allowed to hold at a time
        Use O_DIRECT to bypass OS pager

        implement LRU policy for now, but make it easy to swap algorithms (such as to clock policy or using a nn)
        make a linked list of currently cached blocks
        define MAX_BLOCKS 4
        when we need a block, scan the list and look for it
        if not found, remove last block (flush if necessary) and load in new block from disk 

    tree.c/cursor (in vdb.c) needs a massive rewrite - it's too confusing now
        start with caching the schema instead of dynamically allocating/freeing it in every tree function
        abstraction between cursor and tree is fuzzy - what responsibility should each have?
        traverse_to_first_leaf is no longer necessary - remove it
    
        cursor functions are too light - it should really be calling most of the tree.c api to do what needs to be done
            tree functions should mainly deal with nodes (which the cursor shouldn't know about)

            abstraction layers: vm -> cursor -> tree -> node

            need to pull some complexity out of tree.c and into cursor.c

        cursor abstraction:
            cursors are created when starting a new transaction, and destroyed when transaction ends (commit or not)
            a cursor is associated with a table AND an ordering (eg, by which column the records are indexed)
            a cursor has a closed and open state:
                <open stmt> opens a cursor
                <close stmt>, <commit stmt>, or <rollback stmt> closes cursor
            cursor may be before first record or one past the last record
            fetch - moves cursor to next record and returns that record
            delete - deletes record pointed to by cursor - moves cursor to next record after deletion
            update - updates records pointed to by cursor

    allocated_memory variable show -52 bytes when runnging sol.sql
        I suspect that a non-wrapper allocation function is being called somewhere
        OR free_w has a wrong size argument

    Probably should cached schema and use that whenever vdbmeta_get_schema is called rather than having to
        manually free it every single time - error prone and just makes everything look messier

    User defined primary keys
        Need to make sure keys are unique
        Need to rewrite B-Tree to not always append at end

    Subqueries

    Add tests for errors:
        insert_invalid_col_name.sql <----should report error message.  Silenty failing now when mistyped, and hard to debug
            create table planets (name string, moons int);
            insert into planets (name, gravity) values ("Earth", 9.81); //this should report error instead of setting moons to null and ignoring 9.81

        *will probably need to introduce runtime errors here (we have tokenizing and parsing(?) errors already)

    single line comments
        use c-style //

    multiline comments
        use c-style /**/

    Don't need to specify column names if inserting all values
        insert into planets values (...), (...);

    If block size is 256 and block header size is 128, it crashes if not enough room to store schema data
        the attribute names take too much space.  Need an data blocks and overflow blocks for colunm names

    Compile AST to bytecode that runs on vm
        How could this work?
            what instructions are needed?
        when inserting, attribute names should be parsed as expressions (being parsed as single tokens now)
            can remove parse_identifier_tuple function then

            insert into planets (name, mass) values ("Mars", 242), ("Venus", 242), ("Earth", 534);

        
    need checks to prevent table manipulation/creation/dropping when database not open - segfaulting now

    need to return error if table doesn't exist when insert/select/update/delete - segfaulting now

    primary keys rework
        user MUST define primary key using 'primary key' keywords
        'auto' keyword will make an autoincrementing column value
        'constraint' can be used to set primary key
        should allow this:
            create table planets (name string, moons int);
            create table planets (name string not null, id int auto);
            create table planets (name string, moons int, primary key

    Concurrency - need to get read/write locks on file
        pager can take care of this

    Transactions - need a way of rolling back changes if transaction fails
        need a way to track undos (a stack???)

    Logging - database should never be in inconsistent state if system fails
        sqlite uses a write-ahead log


    Connect cli and the database tree to get useful data - play with MariaDB or MySQL to see how they print outputs
        > open school
            database school opened
        > select * from students
            +----+------+-----+
            | id | name | age |
            +----+------+-----+
            |  1 | John |  23 |
            |  2 | Kate |  12 |
            |  3 | Timm |  22 |
            +----+------+-----+
            3 rows in set
        > close school
            database school closed
            [what message?]

    Foreign keys to connect two or more tables
        joins will be needed here

    Custom keys
        Unique or not?
        Have to rewrite tree to split/merge based on where inserted (since it will not be in order anymore)

    views

    unique constraint

    not null constraint

    group by

    joins
    
    split into client and server - use tcp sockets to connect client to server
